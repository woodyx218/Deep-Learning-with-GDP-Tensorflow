{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Differentially Private Neural Network Tutorial with GDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMXX2M6SDja65O9wCiCGKam",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodyx218/Deep-Learning-with-GDP-Tensorflow/blob/master/GDP_NN_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "temGVWcunZXf"
      },
      "source": [
        "# Differentailly Private Deep Learning accounted by Gaussian differential privacy\n",
        "\n",
        "### This is a tutorial of how to train deep neural networks with differential privacy, a mathematically rigorous privacy definition that defends against privacy leakage, e.g. the [membership inference attack](https://github.com/tensorflow/privacy/tree/master/tensorflow_privacy/privacy/membership_inference_attack).\n",
        "\n",
        "### Our tutorial is based on the Tensorflow privacy library, [**tensorflow-privacy**](https://github.com/tensorflow/privacy). First we install tensorflow-privacy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9qUt7WqoX6L",
        "outputId": "73a504b1-1cd0-4d86-aa20-5679c7c47377"
      },
      "source": [
        "!pip install tensorflow-privacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-privacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/53/31a388f82202a155f248f75cc0f45bd0b85a0ef020a2472e600dc19d38d6/tensorflow_privacy-0.5.2-py3-none-any.whl (192kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 27.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 40kB 21.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 71kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 81kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 92kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 112kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 122kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 133kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 143kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 153kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 163kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 174kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 184kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.4.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.4.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.1.6)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.17->tensorflow-privacy) (1.19.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dm-tree~=0.1.1->tensorflow-privacy) (1.15.0)\n",
            "Installing collected packages: tensorflow-privacy\n",
            "Successfully installed tensorflow-privacy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdP2WEtQx9ls"
      },
      "source": [
        "### We also need the privacy accountants including our GDP accountant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZqPH9b5x8F-",
        "outputId": "7da23861-f52c-4bf3-9e2d-42d800c44c6e"
      },
      "source": [
        "!git clone https://github.com/woodyx218/Deep-Learning-with-GDP-Tensorflow.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-Learning-with-GDP-Tensorflow'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 145 (delta 13), reused 0 (delta 0), pack-reused 119\u001b[K\n",
            "Receiving objects: 100% (145/145), 6.03 MiB | 12.33 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBJdJFTuz5PX",
        "outputId": "2243b2b5-606f-4e4a-ee17-319662f24131"
      },
      "source": [
        "cd /content/Deep-Learning-with-GDP-Tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Deep-Learning-with-GDP-Tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCJ3nkLHondV"
      },
      "source": [
        "### Import necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L6X2njWomvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72998b86-4286-4060-b628-1f19a70d8240"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer import *\n",
        "#DPGradientDescentGaussianOptimizer\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iSmvINfowkc"
      },
      "source": [
        "### We use MNIST here, similar to \n",
        "https://github.com/tensorflow/privacy/blob/master/tutorials/Classification_Privacy.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ubNTL1_vHGg",
        "outputId": "761838fd-774d-4fcb-d9b9-690c2c870854"
      },
      "source": [
        "train, test = tf.keras.datasets.mnist.load_data()\n",
        "train_data, train_labels = train\n",
        "test_data, test_labels = test\n",
        "\n",
        "train_data = np.array(train_data, dtype=np.float32) / 255\n",
        "test_data = np.array(test_data, dtype=np.float32) / 255\n",
        "\n",
        "train_labels = np.array(train_labels, dtype=np.int32).flatten()\n",
        "test_labels = np.array(test_labels, dtype=np.int32).flatten()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr6cvuxTicNX"
      },
      "source": [
        "### Define and tune learning model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JASp1tcViasQ"
      },
      "source": [
        "epochs = 15\n",
        "batch_size = 250\n",
        "\n",
        "l2_norm_clip = 1.5\n",
        "noise_multiplier = 1.3\n",
        "num_microbatches = 250\n",
        "learning_rate = 0.25\n",
        "\n",
        "if batch_size % num_microbatches != 0:\n",
        "  raise ValueError('Batch size should be an integer multiple of the number of microbatches')\n",
        "\n",
        "# indicate whether you want DP\n",
        "dpsgd=True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz8rKavGiwDo"
      },
      "source": [
        "Tensorflow Privacy uses a variant of DP optimizer, known as the microbatch technique. I copy the explanation from their tutorial:\n",
        "\n",
        "---\n",
        "\n",
        "**microbatches (int)** - Each batch of data is split in smaller units called microbatches. By default, each microbatch should contain a single training example. This allows us to clip gradients on a per-example basis rather than after they have been averaged across the minibatch. This in turn decreases the (negative) effect of clipping on signal found in the gradient and typically maximizes utility. However, computational overhead can be reduced by increasing the size of microbatches to include more than one training examples. The average gradient across these multiple training examples is then clipped. The total number of examples consumed in a batch, i.e., one step of gradient descent, remains the same. The number of microbatches should evenly divide the batch size.\n",
        "\n",
        "---\n",
        "\n",
        "If num_microbatches==batch_size, then this is vanilla DP optimizer (e.g. DP-SGD). If not, then DP-SGD is accelerated because you are no longer performing per-sample clipping. E.g. if num_microbatches=50, then you are performing 5-sample clipping for 50 times, instead of per-sample clipping for 250 times. However, this usually worsens the accuracy since the noise is relatively larger.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZVcagU6pkgd"
      },
      "source": [
        "### We define a simple CNN, almost same as [Tensorflow Privacy example](https://github.com/tensorflow/privacy/blob/master/tutorials/Classification_Privacy.ipynb) and [Opacus example](https://github.com/pytorch/opacus/blob/master/examples/mnist.py), but we use **tanh** activation instead of **relu** for better performance (see https://arxiv.org/abs/2007.14191).\n",
        "\n",
        "### Unlike Pytorch, we need to write a custom training function to wrap the model and the optimizer and the loss. You can find other optimizers [here](https://github.com/tensorflow/privacy/blob/master/tensorflow_privacy/privacy/optimizers/dp_optimizer.py). All optimizers can be turned into DP!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajqa_iUctyjY"
      },
      "source": [
        "def cnn_model_fn(features, labels, mode):\n",
        "  \"\"\"Model function for a CNN.\"\"\"\n",
        "\n",
        "  # Define CNN architecture using tf.keras.layers.\n",
        "  input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
        "  y = tf.keras.layers.Conv2D(16, 8,\n",
        "                           strides=2,\n",
        "                           padding='same',\n",
        "                           activation='tanh',\n",
        "                           input_shape=(28, 28, 1))(input_layer)\n",
        "  y = tf.keras.layers.MaxPool2D(2, 1)(y)\n",
        "  y = tf.keras.layers.Conv2D(32, 4,\n",
        "                           strides=2,\n",
        "                           padding='valid',\n",
        "                           activation='tanh')(y)\n",
        "  y = tf.keras.layers.MaxPool2D(2, 1)(y)\n",
        "  y = tf.keras.layers.Flatten()(y)\n",
        "  y = tf.keras.layers.Dense(32, activation='tanh')(y)\n",
        "  logits = tf.keras.layers.Dense(10)(y)\n",
        "\n",
        "  # Calculate loss as a vector (to support microbatches in DP-SGD).\n",
        "  vector_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "      labels=labels, logits=logits)\n",
        "  # Define mean of loss across minibatch (for reporting through tf.Estimator).\n",
        "  scalar_loss = tf.reduce_mean(vector_loss)\n",
        "\n",
        "  # Configure the training op (for TRAIN mode).\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "    if dpsgd:\n",
        "      # Use DP version of GradientDescentOptimizer. Other optimizers are\n",
        "      # available in dp_optimizer. Most optimizers inheriting from\n",
        "      # tf.train.Optimizer should be wrappable in differentially private\n",
        "      # counterparts by calling dp_optimizer.optimizer_from_args().\n",
        "      optimizer = DPGradientDescentGaussianOptimizer(\n",
        "          l2_norm_clip=l2_norm_clip,\n",
        "          noise_multiplier=noise_multiplier,\n",
        "          num_microbatches=num_microbatches,\n",
        "          learning_rate=learning_rate)\n",
        "      opt_loss = vector_loss\n",
        "    else:\n",
        "      optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n",
        "          learning_rate=learning_rate)\n",
        "      opt_loss = scalar_loss\n",
        "    global_step = tf.compat.v1.train.get_global_step()\n",
        "    train_op = optimizer.minimize(loss=opt_loss, global_step=global_step)\n",
        "    # In the following, we pass the mean of the loss (scalar_loss) rather than\n",
        "    # the vector_loss because tf.estimator requires a scalar loss. This is only\n",
        "    # used for evaluation and debugging by tf.estimator. The actual loss being\n",
        "    # minimized is opt_loss defined above and passed to optimizer.minimize().\n",
        "    return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                      loss=scalar_loss,\n",
        "                                      train_op=train_op)\n",
        "\n",
        "  # Add evaluation metrics (for EVAL mode).\n",
        "  elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "    eval_metric_ops = {\n",
        "        'accuracy':\n",
        "            tf.compat.v1.metrics.accuracy(\n",
        "                labels=labels,\n",
        "                predictions=tf.argmax(input=logits, axis=1))\n",
        "    }\n",
        "    return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                      loss=scalar_loss,\n",
        "                                      eval_metric_ops=eval_metric_ops)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-Ninjk_rGiO"
      },
      "source": [
        "### Now that we have the data preprocessed and the model & optimizer defined, we move on to set the training process.\n",
        "\n",
        "### It is important to understand that DP-SGD is implemented differently in TF and Pytorch. TF is significantly slower (e.g. for MNIST, >1 min/epoch; Pytorch Opacus package takes 10 sec/epoch). However, Opacus takes way much memory and thus not suitable for moderately large model. Opacus is also not generalizable (e.g. [cannot do two-layer LSTM](https://github.com/pytorch/opacus/blob/master/tutorials/building_lstm_name_classifier.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi9z0u-rusTh",
        "outputId": "b41bb003-d0e6-47d1-a29f-2f5f8925b742"
      },
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)  # or any {DEBUG, INFO, WARN, ERROR, FATAL}\n",
        "\n",
        "mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\n",
        "\n",
        "  # Create tf.Estimator input functions for the training and test data.\n",
        "eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "    x={'x': test_data},\n",
        "    y=test_labels,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "    x={'x': train_data},\n",
        "    y=train_labels,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=epochs,\n",
        "    shuffle=True)\n",
        "    \n",
        "  # Training loop.\n",
        "steps_per_epoch = 60000 // batch_size\n",
        "test_accuracy_list = []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    np.random.seed(epoch)\n",
        "    # Train the model for one step.\n",
        "    mnist_classifier.train(input_fn=train_input_fn, steps=steps_per_epoch)\n",
        "    \n",
        "    # Evaluate the model and print results\n",
        "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
        "    test_accuracy = eval_results['accuracy']\n",
        "    test_accuracy_list.append(test_accuracy)\n",
        "    print('Test accuracy after %d epochs is: %.3f' % (epoch, test_accuracy))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy after 1 epochs is: 0.908\n",
            "Test accuracy after 2 epochs is: 0.938\n",
            "Test accuracy after 3 epochs is: 0.948\n",
            "Test accuracy after 4 epochs is: 0.955\n",
            "Test accuracy after 5 epochs is: 0.960\n",
            "Test accuracy after 6 epochs is: 0.962\n",
            "Test accuracy after 7 epochs is: 0.964\n",
            "Test accuracy after 8 epochs is: 0.964\n",
            "Test accuracy after 9 epochs is: 0.966\n",
            "Test accuracy after 10 epochs is: 0.968\n",
            "Test accuracy after 11 epochs is: 0.968\n",
            "Test accuracy after 12 epochs is: 0.970\n",
            "Test accuracy after 13 epochs is: 0.968\n",
            "Test accuracy after 14 epochs is: 0.968\n",
            "Test accuracy after 15 epochs is: 0.968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZAhRBhCvusH"
      },
      "source": [
        "### There exist many privacy accountants that give you an upper bound on epsilon. The most popular ones are [Moments Accountant](https://arxiv.org/abs/1607.00133) (MA) and Gaussian DP (GDP; promoted by this paper).\n",
        "\n",
        "### There are many variants of MA. E.g. Opacus uses a version of MA that gives epsilon = 1.32. In below, Tensorflow Privacy uses another MA that gives epsilon = 0.94 and our GDP accountant gives epsilon = 0.82. Hence GDP is the tightest privacy guarantee."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67xQUH1Nt4r2",
        "outputId": "55067bdc-63b2-4951-af59-be47ab7c477e"
      },
      "source": [
        "print('eps_MA by Tensorflow Privacy: ',compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=60000, batch_size=250, noise_multiplier=1.3, epochs=15, delta=1e-5))\n",
        "# or equivalently\n",
        "from gdp_accountant import compute_epsP, compute_epsilon # which uses tensorflow-privacy package\n",
        "print('eps_MA=%.6g' %(compute_epsilon(15,1.3,60000,250,1e-5)))\n",
        "print('eps_GDP=%.6g' %(compute_epsP(15,1.3,60000,250,1e-5)))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DP-SGD with sampling rate = 0.417% and noise_multiplier = 1.3 iterated over 3600 steps satisfies differential privacy with eps = 0.942 and delta = 1e-05.\n",
            "The optimal RDP order is 17.0.\n",
            "eps_MA by Tensorflow Privacy:  (0.9422002181627345, 17.0)\n",
            "eps_MA=0.9422\n",
            "eps_GDP=0.823696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZishKjos1U1"
      },
      "source": [
        "## Some Tips:\n",
        "\n",
        "1. Larger epsilon and delta means model is less private\n",
        "2. Fixing other hyperparameters, more iterations/epochs less private\n",
        "3. Learning rate and clipping norm do not affect DP but affect convergence\n",
        "4. Iteration, sigma, batch size and sample size affect DP\n",
        "5. One set of training corresponds to infinitely many (epsilon,delta) pairs, usually we choose delta = 1/sample size\n",
        "6. Practionally, one tunes clipping norm first with sigma = 0, then fix clipping norm and tune sigma, under pre-specified privacy budget (e.g. epsilon < 8)\n"
      ]
    }
  ]
}